# CSCI_4350_1_28_2019.md

Assignment coming soon

## DFA minimization

* Build a new FA consisting of two states
  * a state corresponding to all of the accepting states
  * a state corresponding to all of the nonaccepting states
* Add corresponding transitions
* If the FA is not deterministic, partition states into smaller subsets until it is a DFA
* The resulting DFA should be minimal

## DFA as recognizer

* Must distinguish between categories of tokens
* Must recognize a sequence of tokens
  ```
  my_var
  /\
  ||
  ```
* The DFA must keep processing character until ther is no transition for the next character
  * If the current state is an accepting state (we are good!) return the token
  * If the current state is a nonaccepting state, then we have got to bascially 'back-up' to the most recent state, or if there isn't one -> report error

## Scanner Implementation

* Automatically generated
  * Table driven
  * direct-coded
* Hand-coded scanner

## Table-driven

* Algorithm + generated tables
* tables
  * Classifier table: map characters to character classes
  * Transition table: encodes transition function
  * token type table: maps accepting states to token categories

## table-driven algorithm

1. Initialize the current state is s_0
                  
                  current string is \epsilon (lexeem)
                  
                  state stack (states in recent memory)
2. Repeatedly read characters and push states until an error state is reached

  * Error state will have to be removed

3. Pop states until an accepting state is reached or the stack is empty

4. If there is an accepting state in your history, return the appropriate token, otherwise return an error

## Direct coded scanner

Also automatically generated, but with a slightly different approach

* table-driven approach requires multiple memory accesses each time the tables are used
* direct-coded approach generates code for what to do be done at each state & jumps to the code for the next state based on the character read.
* implemented using "GOTO"s the scary beast of CSCI 1010
* character classification: easier if consecutive ASCII values
* table_driven may be more efficienct
